{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../globalfunction')  # setting path\n",
    "import globalfunction.vv as vv  # importing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df, data_version_description, numeric_cols, cat_cols = vv.dataset_modelling_version(iteration_code=\"0011_20220703\", row_limit=100)\n",
    "#df, data_version_description, numeric_cols, cat_cols = vv.dataset_modelling_version(iteration_code=\"0011_20220703\", row_limit=500)\n",
    "df, data_version_description, numeric_cols, cat_cols = vv.dataset_modelling_version(iteration_code=\"0011_20220703\", row_limit=8000)\n",
    "#df, data_version_description, numeric_cols, cat_cols = vv.dataset_modelling_version(iteration_code=\"0011_20220703\", row_limit=0)\n",
    "print(data_version_description)\n",
    "print(df.shape)\n",
    "df.sample(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = vv.tidy_dataset(df, coerce_to_float=['location.latitude'], na_infer_median=['bedrooms_model', 'bathrooms_model'], na_drop_column=[],\n",
    "                     na_drop_rows=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_incomplete_rows = df[df.isnull().any(axis=1)]  #.head()\n",
    "sample_incomplete_rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = df['Price']\n",
    "X = df.drop(['Price'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=101)\n",
    "X_train.shape, X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])  # define the transformer for categorical columns\n",
    "\n",
    "numeric_no_scale_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])  # define the transformer for categorical columns\n",
    "\n",
    "categorical_transformer1 = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "categorical_transformer2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "features_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_transformer,\n",
    "         ['location.latitude', 'location.longitude', 'distance_to_any_train', 'bedrooms_model', 'bathrooms_model', 'analyticsProperty.imageCount', 'analyticsProperty.added',\n",
    "          'floorplan_count', 'property_age']),\n",
    "        ('categorical1', categorical_transformer1, []),  #\n",
    "        ('categorical2', categorical_transformer2, [])\n",
    "    ])\n",
    "features_noscale_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_no_scale_transformer,\n",
    "         ['location.latitude', 'location.longitude', 'distance_to_any_train', 'bedrooms_model', 'bathrooms_model', 'analyticsProperty.imageCount', 'analyticsProperty.added',\n",
    "          'floorplan_count']),\n",
    "        ('categorical1', categorical_transformer1, []),\n",
    "        ('categorical2', categorical_transformer2, [])\n",
    "    ])\n",
    "\n",
    "features_preprocessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_noscale_preprocessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EstimatorPipeSelectionHelper:\n",
    "\n",
    "    def __init__(self, models_and_params):\n",
    "        # if not set(models.keys()).issubset(set(params.keys())):\n",
    "        #     missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "        #     raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        # self.models = models\n",
    "        # self.params = params\n",
    "        # self.keys = models.keys()\n",
    "        self.keys = models_and_params.keys()\n",
    "        self.models_and_params = models_and_params\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False, n_iter=10):\n",
    "        for key in self.keys:\n",
    "            model = self.models_and_params[key][\"model\"]\n",
    "            params = self.models_and_params[key][\"params\"]\n",
    "\n",
    "            if 'noscale' in key:\n",
    "                pipe = Pipeline(steps=[\n",
    "                    ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "                    ('estimator', model),\n",
    "                ])  # start the training\n",
    "            else:\n",
    "                pipe = Pipeline(steps=[\n",
    "                    ('preprocessor', features_preprocessor),  # preprocess features\n",
    "                    ('estimator', model),\n",
    "                ])  # start the training\n",
    "\n",
    "            if self.models_and_params[key][\"cv_type\"] == 'grid':\n",
    "                print(\"Running GridSearchCV for %s.\" % key)\n",
    "                gs = GridSearchCV(pipe, params, cv=cv, n_jobs=n_jobs,\n",
    "                                  verbose=verbose, scoring=scoring, refit=refit,\n",
    "                                  return_train_score=True)\n",
    "                gs.fit(X, y)\n",
    "                self.grid_searches[key] = gs\n",
    "            elif self.models_and_params[key][\"cv_type\"] == 'random':\n",
    "                print(\"Running RandomizedSearchCV for %s.\" % key)\n",
    "                gs = RandomizedSearchCV(pipe, params, cv=cv, n_jobs=n_jobs,\n",
    "                                  verbose=verbose, scoring=scoring, refit=refit,\n",
    "                                  return_train_score=True,n_iter=n_iter)\n",
    "                gs.fit(X, y)\n",
    "                self.grid_searches[key] = gs\n",
    "            else:\n",
    "                raise ValueError()\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            #return pd.Series({**params, **d})\n",
    "            return pd.Series({**params, **d, **{'params_full': str(params)}})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options__maxdepth = [3, 5, 10, 50, 100, 200, 250, 300, 350, 400, 500]\n",
    "options__nestimators = [5, 50, 100, 500, 1000, 2000, 5000]\n",
    "\n",
    "models_and_params = {\n",
    "    'RF scaled random': {\n",
    "        'model': RandomForestRegressor(random_state=101),\n",
    "        'params': {'estimator__max_depth': options__maxdepth,\n",
    "                   'estimator__n_estimators': options__nestimators},\n",
    "        'cv_type': 'random'\n",
    "    },\n",
    "    'RF noscale random': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'estimator__max_depth': options__maxdepth,\n",
    "                   'estimator__n_estimators': options__nestimators},\n",
    "        'cv_type': 'random'\n",
    "    },\n",
    "    # 'RF scaled max depth': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__max_depth': options__maxdepth},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    # 'RF noscale max depth': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__max_depth': options__maxdepth},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    # 'RF scaled nestimators': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__n_estimators': options__nestimators},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    # 'RF noscale nestimators': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__n_estimators': options__nestimators},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    # 'RF redundancy 1': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__n_estimators': [5]},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    # 'RF redundancy 2': {\n",
    "    #     'model': RandomForestRegressor(),\n",
    "    #     'params': {'estimator__n_estimators': [5]},\n",
    "    #     'cv_type': 'grid'\n",
    "    # },\n",
    "    'RF scaled 1 (scaled vs not)': {\n",
    "        'model': RandomForestRegressor(random_state=101),\n",
    "        'params': {'estimator__n_estimators': [5]},\n",
    "        'cv_type': 'grid'\n",
    "    },\n",
    "    'RF scaled 2 (scaled vs not)': {\n",
    "        'model': RandomForestRegressor(random_state=101),\n",
    "        'params': {'estimator__n_estimators': [5]},\n",
    "        'cv_type': 'grid'\n",
    "    },\n",
    "    'RF noscaled (scaled vs not)': {\n",
    "        'model': RandomForestRegressor(random_state=101),\n",
    "        'params': {'estimator__n_estimators': [5]},\n",
    "        'cv_type': 'grid'\n",
    "    }\n",
    "}\n",
    "\n",
    "helper = EstimatorPipeSelectionHelper(models_and_params)\n",
    "helper.fit(X_train, y_train, scoring='neg_root_mean_squared_error', n_jobs=2, cv=2, n_iter=5)\n",
    "\n",
    "score_summary = helper.score_summary(sort_by='max_score')\n",
    "score_summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    if False:\n",
    "        sns.plotting_context()\n",
    "        # https://seaborn.pydata.org/generated/seaborn.set_theme.html#seaborn.set_theme\n",
    "\n",
    "    best_estimator = score_summary.iloc[0]\n",
    "    worst_estimator = score_summary.iloc[-1]\n",
    "    best_estimator, worst_estimator\n",
    "\n",
    "    name_best = best_estimator[\"estimator\"]\n",
    "    params_str = best_estimator[\"params_full\"]\n",
    "\n",
    "    params_best = ast.literal_eval(params_str)\n",
    "    print(\"best\", params_best)\n",
    "    RandomForestRegressor().set_params()\n",
    "\n",
    "    if 'noscale' in name_best:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "            ('estimator', models1[name_best]),\n",
    "        ])  # start the training\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_preprocessor),\n",
    "            ('estimator', models1[name_best]),  # preprocess features\n",
    "        ])  # start the training\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, pipe.set_params(**params_best).fit(X_train, y_train).predict(X_test), edgecolors=(0, 0, 1))\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.title.set_text(f'best model: {name_best} {params_best}')\n",
    "\n",
    "    name_worst = worst_estimator[\"estimator\"]\n",
    "    params_str = worst_estimator[\"params_full\"]\n",
    "\n",
    "    params_worst = ast.literal_eval(params_str)\n",
    "    print(\"worst\", params_worst)\n",
    "\n",
    "    if 'noscale' in name_worst:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "            ('estimator', models1[name_worst]),\n",
    "        ])  # start the training\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_preprocessor),\n",
    "            ('estimator', models1[name_worst]),  # preprocess features\n",
    "        ])  # start the training\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, pipe.set_params(**params_worst).fit(X_train, y_train).predict(X_test), edgecolors=(0, 0, 1))\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.title.set_text(f'worst model: {name_worst} {params_worst}')\n",
    "\n",
    "\n",
    "def make_pipe(name):\n",
    "    if 'noscale' in name:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "            ('estimator', models_and_params[name][\"model\"]),\n",
    "        ])  # start the training\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', features_preprocessor),\n",
    "            ('estimator', models_and_params[name][\"model\"]),  # preprocess features\n",
    "        ])  # start the training\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "if True:\n",
    "    #sns.set(rc={\"figure.figsize\": (10, 10)})\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    #total_graphs = len(score_summary)\n",
    "    # max_horizontal = 4\n",
    "    # index2 = 0\n",
    "    # resultant_rows = math.ceil(total_graphs / max_horizontal)\n",
    "    # #subplots_adjust()\n",
    "    #\n",
    "    # #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    best_estimator = score_summary.iloc[0]\n",
    "    worst_estimator = score_summary.iloc[-1]\n",
    "\n",
    "    name_best = best_estimator[\"estimator\"]\n",
    "    params_str = best_estimator[\"params_full\"]\n",
    "    params_best = ast.literal_eval(params_str)\n",
    "\n",
    "    name_worst = worst_estimator[\"estimator\"]\n",
    "    params_str = worst_estimator[\"params_full\"]\n",
    "    params_worst = ast.literal_eval(params_str)\n",
    "\n",
    "    RandomForestRegressor().set_params()\n",
    "\n",
    "    best_pipe = make_pipe(name_best)\n",
    "    worst_pipe = make_pipe(name_worst)\n",
    "\n",
    "    coordinates = axes[0]\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[0], color='red')\n",
    "    sns.scatterplot(x=y_test, y=best_pipe.set_params(**params_best).fit(X_train, y_train).predict(X_test), ax=axes[0], s=100).set(\n",
    "        title=f'\"BEST\" model: {name_best} \\n{params_best}')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[1], color='red')\n",
    "    sns.scatterplot(x=y_test, y=worst_pipe.set_params(**params_worst).fit(X_train, y_train).predict(X_test), ax=axes[1], s=100).set(\n",
    "        title=f'\"WORST\" model: {name_worst} \\n{params_worst}')\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=worst_pipe.set_params(**params_worst).fit(X_train, y_train).predict(X_test), ax=axes[2], s=100, color='orange')\n",
    "    sns.scatterplot(x=y_test, y=best_pipe.set_params(**params_best).fit(X_train, y_train).predict(X_test), ax=axes[2], s=100, alpha=0.6, color='black').set(\n",
    "        title='best (black) vs worst (orange)')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if True:\n",
    "    max_horizontal = 3\n",
    "\n",
    "    #sns.set()\n",
    "    #sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "    sns.set(rc={\"figure.figsize\": (20, 20)})\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    total_graphs = len(score_summary)\n",
    "    index2 = 0\n",
    "    resultant_rows = math.ceil(total_graphs / max_horizontal)\n",
    "    #subplots_adjust()\n",
    "\n",
    "    #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=max_horizontal, figsize=(15, 10))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    for (key, next_estimator), index in zip(score_summary.iterrows(), range(total_graphs)):\n",
    "        if index % (max_horizontal * 2) == 0 and index != 0:\n",
    "            index2 = 0\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=max_horizontal, figsize=(15, 10))\n",
    "\n",
    "        name_next = next_estimator[\"estimator\"]\n",
    "        params_str = next_estimator[\"params_full\"]\n",
    "        params_next = ast.literal_eval(params_str)\n",
    "        #print(\"next\", params_next)\n",
    "\n",
    "        if 'noscale' in name_next:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "                ('estimator', models_and_params[name_next][\"model\"]),\n",
    "            ])  # start the training\n",
    "        else:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('preprocessor', features_preprocessor),\n",
    "                ('estimator', models_and_params[name_next][\"model\"]),  # preprocess features\n",
    "            ])  # start the training\n",
    "\n",
    "        # 0 ==> 0,0\n",
    "        # 1 ==> 0,1\n",
    "        # 2 ==> 1,0\n",
    "        x_coor = index2 // max_horizontal\n",
    "        y_coor = index2 % max_horizontal\n",
    "\n",
    "        coordinates = axes[x_coor][y_coor]\n",
    "        #sns.lineplot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], hue='red', lw=3)\n",
    "        sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=coordinates, color='red')\n",
    "        sns.scatterplot(x=y_test, y=pipe.set_params(**params_next).fit(X_train, y_train).predict(X_test), ax=coordinates, s=100).set(\n",
    "            title=f'({index}) {\"BEST\" if index == 0 else \"next\"} model: {name_next} \\n{params_next}')\n",
    "        #if index == 11: break\n",
    "        index2 += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}